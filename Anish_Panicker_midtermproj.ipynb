{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "from collections import defaultdict\n",
        "import time\n",
        "from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth\n",
        "\n",
        "datasets = {\n",
        "    1: 'amazon_items.csv',\n",
        "    2: 'bestbuy_items.csv',\n",
        "    3: 'kmart_items.csv',\n",
        "    4: 'target_items.csv',\n",
        "    5: 'walmart_items.csv'\n",
        "}\n",
        "\n",
        "print(\"Available Datasets:\")\n",
        "for key, value in datasets.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "dataset_choice = int(input(\"Enter the dataset number you want to load (1-5): \"))\n",
        "\n",
        "if dataset_choice in datasets:\n",
        "    dataset_path = datasets[dataset_choice]\n",
        "    df = pd.read_csv(dataset_path)\n",
        "    print(f\"\\nLoaded dataset from: {dataset_path}\")\n",
        "    print(df.head())\n",
        "\n",
        "    transactions = df['Items'].apply(lambda x: x.split(', ')).tolist()\n",
        "    all_items = sorted(set(item for transaction in transactions for item in transaction))\n",
        "\n",
        "    print(\"Transactions:\", transactions)\n",
        "    print(\"Number of Transactions:\", len(transactions))\n",
        "    print(\"All Unique Items:\", all_items)\n",
        "    print(\"Number of Unique Items:\", len(all_items))\n",
        "else:\n",
        "    print(\"Invalid choice. Please select a number between 1 and 5.\")\n",
        "\n",
        "min_support = float(input(\"Enter the minimum support value: \"))\n",
        "min_confidence = float(input(\"Enter the minimum confidence value: \"))\n",
        "\n",
        "transaction_df = pd.DataFrame([{item: (item in transaction) for item in all_items} for transaction in transactions])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GkCdPpQflYy",
        "outputId": "c8c24203-714b-4169-9335-c9bd1287acde"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available Datasets:\n",
            "1: /content/amazon_items - Sheet1.csv\n",
            "2: /content/bestbuy_items - Sheet1.csv\n",
            "3: /content/kmart_items - Sheet1 (1).csv\n",
            "4: /content/target_items - Sheet1 (1).csv\n",
            "5: /content/walmart_items - Sheet1.csv\n",
            "Enter the dataset number you want to load (1-5): 1\n",
            "\n",
            "Loaded dataset from: /content/amazon_items - Sheet1.csv\n",
            "   TransactionID                                      Items\n",
            "0              1  Kindle, Cable, Stand, Smartwatch, Headset\n",
            "1              2       Fire, Kindle, Echo, Charger, Speaker\n",
            "2              3    Smartwatch, Stand, Cable, Charger, Fire\n",
            "3              4      Echo, Kindle, Fire, Smartwatch, Cable\n",
            "4              5       Laptop, Charger, Smartwatch, Headset\n",
            "Transactions: [['Kindle', 'Cable', 'Stand', 'Smartwatch', 'Headset'], ['Fire', 'Kindle', 'Echo', 'Charger', 'Speaker'], ['Smartwatch', 'Stand', 'Cable', 'Charger', 'Fire'], ['Echo', 'Kindle', 'Fire', 'Smartwatch', 'Cable'], ['Laptop', 'Charger', 'Smartwatch', 'Headset'], ['Kindle', 'Cable', 'Speaker', 'Echo', 'Smartwatch'], ['Stand', 'Fire', 'Speaker', 'Charger'], ['Kindle', 'Headset', 'Cable', 'Echo'], ['Laptop', 'Speaker', 'Echo', 'Fire', 'Smartwatch'], ['Kindle', 'Charger', 'Headset', 'Smartwatch', 'Cable'], ['Fire', 'Smartwatch', 'Speaker', 'Stand'], ['Kindle', 'Headset', 'Stand', 'Cable'], ['Smartwatch', 'Echo', 'Fire', 'Cable'], ['Kindle', 'Charger', 'Echo', 'Smartwatch'], ['Speaker', 'Laptop', 'Cable', 'Fire'], ['Echo', 'Kindle', 'Headset', 'Charger'], ['Smartwatch', 'Stand', 'Speaker', 'Echo'], ['Fire', 'Cable', 'Charger', 'Smartwatch'], ['Laptop', 'Kindle', 'Headset', 'Cable'], ['Echo', 'Speaker', 'Stand', 'Smartwatch'], ['Cable', 'Charger', 'Fire', 'Smartwatch'], ['Headset', 'Kindle', 'Laptop', 'Speaker'], ['Fire', 'Echo', 'Charger', 'Cable'], ['Kindle', 'Echo', 'Smartwatch', 'Speaker'], ['Stand', 'Charger', 'Smartwatch', 'Fire']]\n",
            "Number of Transactions: 25\n",
            "All Unique Items: ['Cable', 'Charger', 'Echo', 'Fire', 'Headset', 'Kindle', 'Laptop', 'Smartwatch', 'Speaker', 'Stand']\n",
            "Number of Unique Items: 10\n",
            "Enter the minimum support value: 0.2\n",
            "Enter the minimum confidence value: 0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_candidates(itemset, length):\n",
        "    \"\"\"Generate all combinations of itemsets of a given length.\"\"\"\n",
        "    return list(itertools.combinations(itemset, length))\n",
        "\n",
        "def calculate_support(itemset, transactions):\n",
        "    \"\"\"Calculate support of an itemset.\"\"\"\n",
        "    count = 0\n",
        "    for transaction in transactions:\n",
        "        if all(item in transaction for item in itemset):\n",
        "            count += 1\n",
        "    return count / len(transactions)\n",
        "\n",
        "def generate_frequent_itemsets(transactions, all_items, min_support):\n",
        "\n",
        "    frequent_itemsets = []\n",
        "    k = 1\n",
        "    while True:\n",
        "        candidate_itemsets = generate_candidates(all_items, k)\n",
        "        current_frequent_itemsets = []\n",
        "\n",
        "\n",
        "        for itemset in candidate_itemsets:\n",
        "            support = calculate_support(itemset, transactions)\n",
        "            if support >= min_support:\n",
        "                current_frequent_itemsets.append((itemset, support))\n",
        "\n",
        "        if not current_frequent_itemsets:\n",
        "            break\n",
        "\n",
        "\n",
        "        frequent_itemsets.extend(current_frequent_itemsets)\n",
        "        k += 1\n",
        "\n",
        "    return frequent_itemsets\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "frequent_itemsets = generate_frequent_itemsets(transactions, all_items, min_support)\n",
        "end_time = time.time()\n",
        "bf_time = end_time - start_time\n",
        "\n",
        "print(\"\\nFrequent Itemsets:\")\n",
        "for itemset, support in frequent_itemsets:\n",
        "    print(f\"Itemset: {itemset}, Support: {support}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU57aaPQf2r9",
        "outputId": "c7431bdc-cfce-4fe9-c45e-f7c70f77919b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Frequent Itemsets:\n",
            "Itemset: ('Cable',), Support: 0.52\n",
            "Itemset: ('Charger',), Support: 0.44\n",
            "Itemset: ('Echo',), Support: 0.48\n",
            "Itemset: ('Fire',), Support: 0.48\n",
            "Itemset: ('Headset',), Support: 0.32\n",
            "Itemset: ('Kindle',), Support: 0.48\n",
            "Itemset: ('Laptop',), Support: 0.2\n",
            "Itemset: ('Smartwatch',), Support: 0.64\n",
            "Itemset: ('Speaker',), Support: 0.4\n",
            "Itemset: ('Stand',), Support: 0.32\n",
            "Itemset: ('Cable', 'Charger'), Support: 0.2\n",
            "Itemset: ('Cable', 'Echo'), Support: 0.2\n",
            "Itemset: ('Cable', 'Fire'), Support: 0.28\n",
            "Itemset: ('Cable', 'Headset'), Support: 0.2\n",
            "Itemset: ('Cable', 'Kindle'), Support: 0.28\n",
            "Itemset: ('Cable', 'Smartwatch'), Support: 0.32\n",
            "Itemset: ('Charger', 'Fire'), Support: 0.28\n",
            "Itemset: ('Charger', 'Smartwatch'), Support: 0.28\n",
            "Itemset: ('Echo', 'Fire'), Support: 0.2\n",
            "Itemset: ('Echo', 'Kindle'), Support: 0.28\n",
            "Itemset: ('Echo', 'Smartwatch'), Support: 0.32\n",
            "Itemset: ('Echo', 'Speaker'), Support: 0.24\n",
            "Itemset: ('Fire', 'Smartwatch'), Support: 0.32\n",
            "Itemset: ('Fire', 'Speaker'), Support: 0.2\n",
            "Itemset: ('Headset', 'Kindle'), Support: 0.28\n",
            "Itemset: ('Kindle', 'Smartwatch'), Support: 0.24\n",
            "Itemset: ('Smartwatch', 'Speaker'), Support: 0.24\n",
            "Itemset: ('Smartwatch', 'Stand'), Support: 0.24\n",
            "Itemset: ('Cable', 'Fire', 'Smartwatch'), Support: 0.2\n",
            "Itemset: ('Cable', 'Headset', 'Kindle'), Support: 0.2\n",
            "Itemset: ('Echo', 'Smartwatch', 'Speaker'), Support: 0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_association_rules(frequent_itemsets, min_confidence):\n",
        "    rules = []\n",
        "    for itemset, support in frequent_itemsets:\n",
        "        if len(itemset) < 2:\n",
        "            continue\n",
        "        for i in range(1, len(itemset)):\n",
        "            antecedents = list(itertools.combinations(itemset, i))\n",
        "            for antecedent in antecedents:\n",
        "                consequent = tuple(item for item in itemset if item not in antecedent)\n",
        "                antecedent_support = calculate_support(antecedent, transactions)\n",
        "                if antecedent_support > 0:\n",
        "                    confidence = support / antecedent_support\n",
        "                    if confidence >= min_confidence:\n",
        "                        rules.append((antecedent, consequent, support, confidence))\n",
        "    return rules\n",
        "\n",
        "association_rules_bf = generate_association_rules(frequent_itemsets, min_confidence)\n",
        "print(\"\\nAssociation Rules (Brute Force):\")\n",
        "for antecedent, consequent, support, confidence in association_rules_bf:\n",
        "    print(f\"Rule: {antecedent} -> {consequent}, Support: {support}, Confidence: {confidence}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0fMdO0bfyx6",
        "outputId": "6710bbc7-3c72-4c7c-be86-b6341710a20f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Association Rules (Brute Force):\n",
            "Rule: ('Cable',) -> ('Fire',), Support: 0.28, Confidence: 0.5384615384615385\n",
            "Rule: ('Fire',) -> ('Cable',), Support: 0.28, Confidence: 0.5833333333333334\n",
            "Rule: ('Headset',) -> ('Cable',), Support: 0.2, Confidence: 0.625\n",
            "Rule: ('Cable',) -> ('Kindle',), Support: 0.28, Confidence: 0.5384615384615385\n",
            "Rule: ('Kindle',) -> ('Cable',), Support: 0.28, Confidence: 0.5833333333333334\n",
            "Rule: ('Cable',) -> ('Smartwatch',), Support: 0.32, Confidence: 0.6153846153846154\n",
            "Rule: ('Smartwatch',) -> ('Cable',), Support: 0.32, Confidence: 0.5\n",
            "Rule: ('Charger',) -> ('Fire',), Support: 0.28, Confidence: 0.6363636363636365\n",
            "Rule: ('Fire',) -> ('Charger',), Support: 0.28, Confidence: 0.5833333333333334\n",
            "Rule: ('Charger',) -> ('Smartwatch',), Support: 0.28, Confidence: 0.6363636363636365\n",
            "Rule: ('Echo',) -> ('Kindle',), Support: 0.28, Confidence: 0.5833333333333334\n",
            "Rule: ('Kindle',) -> ('Echo',), Support: 0.28, Confidence: 0.5833333333333334\n",
            "Rule: ('Echo',) -> ('Smartwatch',), Support: 0.32, Confidence: 0.6666666666666667\n",
            "Rule: ('Smartwatch',) -> ('Echo',), Support: 0.32, Confidence: 0.5\n",
            "Rule: ('Echo',) -> ('Speaker',), Support: 0.24, Confidence: 0.5\n",
            "Rule: ('Speaker',) -> ('Echo',), Support: 0.24, Confidence: 0.6\n",
            "Rule: ('Fire',) -> ('Smartwatch',), Support: 0.32, Confidence: 0.6666666666666667\n",
            "Rule: ('Smartwatch',) -> ('Fire',), Support: 0.32, Confidence: 0.5\n",
            "Rule: ('Speaker',) -> ('Fire',), Support: 0.2, Confidence: 0.5\n",
            "Rule: ('Headset',) -> ('Kindle',), Support: 0.28, Confidence: 0.8750000000000001\n",
            "Rule: ('Kindle',) -> ('Headset',), Support: 0.28, Confidence: 0.5833333333333334\n",
            "Rule: ('Kindle',) -> ('Smartwatch',), Support: 0.24, Confidence: 0.5\n",
            "Rule: ('Speaker',) -> ('Smartwatch',), Support: 0.24, Confidence: 0.6\n",
            "Rule: ('Stand',) -> ('Smartwatch',), Support: 0.24, Confidence: 0.75\n",
            "Rule: ('Cable', 'Fire') -> ('Smartwatch',), Support: 0.2, Confidence: 0.7142857142857143\n",
            "Rule: ('Cable', 'Smartwatch') -> ('Fire',), Support: 0.2, Confidence: 0.625\n",
            "Rule: ('Fire', 'Smartwatch') -> ('Cable',), Support: 0.2, Confidence: 0.625\n",
            "Rule: ('Headset',) -> ('Cable', 'Kindle'), Support: 0.2, Confidence: 0.625\n",
            "Rule: ('Cable', 'Headset') -> ('Kindle',), Support: 0.2, Confidence: 1.0\n",
            "Rule: ('Cable', 'Kindle') -> ('Headset',), Support: 0.2, Confidence: 0.7142857142857143\n",
            "Rule: ('Headset', 'Kindle') -> ('Cable',), Support: 0.2, Confidence: 0.7142857142857143\n",
            "Rule: ('Speaker',) -> ('Echo', 'Smartwatch'), Support: 0.2, Confidence: 0.5\n",
            "Rule: ('Echo', 'Smartwatch') -> ('Speaker',), Support: 0.2, Confidence: 0.625\n",
            "Rule: ('Echo', 'Speaker') -> ('Smartwatch',), Support: 0.2, Confidence: 0.8333333333333334\n",
            "Rule: ('Smartwatch', 'Speaker') -> ('Echo',), Support: 0.2, Confidence: 0.8333333333333334\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apriori\n",
        "start_time = time.time()\n",
        "frequent_itemsets_apriori = apriori(transaction_df, min_support=min_support, use_colnames=True)\n",
        "end_time = time.time()\n",
        "apriori_time = end_time - start_time\n",
        "\n",
        "association_rules_apriori = association_rules(frequent_itemsets_apriori, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "print(\"\\nFrequent Itemsets (Apriori):\")\n",
        "print(frequent_itemsets_apriori)\n",
        "print(\"\\nAssociation Rules (Apriori):\")\n",
        "for _, row in association_rules_apriori.iterrows():\n",
        "    print(f\"Rule: {tuple(row['antecedents'])} -> {tuple(row['consequents'])}, Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "697RouhKgS1W",
        "outputId": "6f2a4ce7-69c3-4870-f6e1-b6faf1530216"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Frequent Itemsets (Apriori):\n",
            "    support                     itemsets\n",
            "0      0.52                      (Cable)\n",
            "1      0.44                    (Charger)\n",
            "2      0.48                       (Echo)\n",
            "3      0.48                       (Fire)\n",
            "4      0.32                    (Headset)\n",
            "5      0.48                     (Kindle)\n",
            "6      0.20                     (Laptop)\n",
            "7      0.64                 (Smartwatch)\n",
            "8      0.40                    (Speaker)\n",
            "9      0.32                      (Stand)\n",
            "10     0.20             (Charger, Cable)\n",
            "11     0.20                (Echo, Cable)\n",
            "12     0.28                (Cable, Fire)\n",
            "13     0.20             (Headset, Cable)\n",
            "14     0.28              (Kindle, Cable)\n",
            "15     0.32          (Smartwatch, Cable)\n",
            "16     0.28              (Charger, Fire)\n",
            "17     0.28        (Charger, Smartwatch)\n",
            "18     0.20                 (Echo, Fire)\n",
            "19     0.28               (Kindle, Echo)\n",
            "20     0.32           (Smartwatch, Echo)\n",
            "21     0.24              (Speaker, Echo)\n",
            "22     0.32           (Smartwatch, Fire)\n",
            "23     0.20              (Speaker, Fire)\n",
            "24     0.28            (Kindle, Headset)\n",
            "25     0.24         (Smartwatch, Kindle)\n",
            "26     0.24        (Speaker, Smartwatch)\n",
            "27     0.24          (Smartwatch, Stand)\n",
            "28     0.20    (Smartwatch, Cable, Fire)\n",
            "29     0.20     (Kindle, Headset, Cable)\n",
            "30     0.20  (Speaker, Smartwatch, Echo)\n",
            "\n",
            "Association Rules (Apriori):\n",
            "Rule: ('Cable',) -> ('Fire',), Support: 0.2800, Confidence: 0.5385\n",
            "Rule: ('Fire',) -> ('Cable',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Headset',) -> ('Cable',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Kindle',) -> ('Cable',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Cable',) -> ('Kindle',), Support: 0.2800, Confidence: 0.5385\n",
            "Rule: ('Smartwatch',) -> ('Cable',), Support: 0.3200, Confidence: 0.5000\n",
            "Rule: ('Cable',) -> ('Smartwatch',), Support: 0.3200, Confidence: 0.6154\n",
            "Rule: ('Charger',) -> ('Fire',), Support: 0.2800, Confidence: 0.6364\n",
            "Rule: ('Fire',) -> ('Charger',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Charger',) -> ('Smartwatch',), Support: 0.2800, Confidence: 0.6364\n",
            "Rule: ('Kindle',) -> ('Echo',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Echo',) -> ('Kindle',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Smartwatch',) -> ('Echo',), Support: 0.3200, Confidence: 0.5000\n",
            "Rule: ('Echo',) -> ('Smartwatch',), Support: 0.3200, Confidence: 0.6667\n",
            "Rule: ('Speaker',) -> ('Echo',), Support: 0.2400, Confidence: 0.6000\n",
            "Rule: ('Echo',) -> ('Speaker',), Support: 0.2400, Confidence: 0.5000\n",
            "Rule: ('Smartwatch',) -> ('Fire',), Support: 0.3200, Confidence: 0.5000\n",
            "Rule: ('Fire',) -> ('Smartwatch',), Support: 0.3200, Confidence: 0.6667\n",
            "Rule: ('Speaker',) -> ('Fire',), Support: 0.2000, Confidence: 0.5000\n",
            "Rule: ('Kindle',) -> ('Headset',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Headset',) -> ('Kindle',), Support: 0.2800, Confidence: 0.8750\n",
            "Rule: ('Kindle',) -> ('Smartwatch',), Support: 0.2400, Confidence: 0.5000\n",
            "Rule: ('Speaker',) -> ('Smartwatch',), Support: 0.2400, Confidence: 0.6000\n",
            "Rule: ('Stand',) -> ('Smartwatch',), Support: 0.2400, Confidence: 0.7500\n",
            "Rule: ('Smartwatch', 'Cable') -> ('Fire',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Smartwatch', 'Fire') -> ('Cable',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Cable', 'Fire') -> ('Smartwatch',), Support: 0.2000, Confidence: 0.7143\n",
            "Rule: ('Kindle', 'Headset') -> ('Cable',), Support: 0.2000, Confidence: 0.7143\n",
            "Rule: ('Kindle', 'Cable') -> ('Headset',), Support: 0.2000, Confidence: 0.7143\n",
            "Rule: ('Headset', 'Cable') -> ('Kindle',), Support: 0.2000, Confidence: 1.0000\n",
            "Rule: ('Headset',) -> ('Kindle', 'Cable'), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Speaker', 'Smartwatch') -> ('Echo',), Support: 0.2000, Confidence: 0.8333\n",
            "Rule: ('Speaker', 'Echo') -> ('Smartwatch',), Support: 0.2000, Confidence: 0.8333\n",
            "Rule: ('Smartwatch', 'Echo') -> ('Speaker',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Speaker',) -> ('Smartwatch', 'Echo'), Support: 0.2000, Confidence: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FP-Growth\n",
        "start_time = time.time()\n",
        "frequent_itemsets_fpgrowth = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)\n",
        "end_time = time.time()\n",
        "fpgrowth_time = end_time - start_time\n",
        "\n",
        "association_rules_fpgrowth = association_rules(frequent_itemsets_fpgrowth, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "print(\"\\nFrequent Itemsets (FP-Growth):\")\n",
        "print(frequent_itemsets_fpgrowth)\n",
        "print(\"\\nAssociation Rules (FP-Growth):\")\n",
        "for _, row in association_rules_fpgrowth.iterrows():\n",
        "    print(f\"Rule: {tuple(row['antecedents'])} -> {tuple(row['consequents'])}, Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi52y75rg3Xr",
        "outputId": "bdc8110c-dd33-46b1-a321-e02f833c988d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Frequent Itemsets (FP-Growth):\n",
            "    support                     itemsets\n",
            "0      0.64                 (Smartwatch)\n",
            "1      0.52                      (Cable)\n",
            "2      0.48                     (Kindle)\n",
            "3      0.32                      (Stand)\n",
            "4      0.32                    (Headset)\n",
            "5      0.48                       (Fire)\n",
            "6      0.48                       (Echo)\n",
            "7      0.44                    (Charger)\n",
            "8      0.40                    (Speaker)\n",
            "9      0.20                     (Laptop)\n",
            "10     0.32          (Smartwatch, Cable)\n",
            "11     0.28              (Kindle, Cable)\n",
            "12     0.24         (Smartwatch, Kindle)\n",
            "13     0.24          (Smartwatch, Stand)\n",
            "14     0.28            (Kindle, Headset)\n",
            "15     0.20             (Headset, Cable)\n",
            "16     0.20     (Kindle, Headset, Cable)\n",
            "17     0.32           (Smartwatch, Fire)\n",
            "18     0.28                (Cable, Fire)\n",
            "19     0.20    (Smartwatch, Cable, Fire)\n",
            "20     0.28               (Kindle, Echo)\n",
            "21     0.20                 (Echo, Fire)\n",
            "22     0.32           (Smartwatch, Echo)\n",
            "23     0.20                (Echo, Cable)\n",
            "24     0.28              (Charger, Fire)\n",
            "25     0.28        (Charger, Smartwatch)\n",
            "26     0.20             (Charger, Cable)\n",
            "27     0.24              (Speaker, Echo)\n",
            "28     0.20              (Speaker, Fire)\n",
            "29     0.24        (Speaker, Smartwatch)\n",
            "30     0.20  (Speaker, Smartwatch, Echo)\n",
            "\n",
            "Association Rules (FP-Growth):\n",
            "Rule: ('Smartwatch',) -> ('Cable',), Support: 0.3200, Confidence: 0.5000\n",
            "Rule: ('Cable',) -> ('Smartwatch',), Support: 0.3200, Confidence: 0.6154\n",
            "Rule: ('Kindle',) -> ('Cable',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Cable',) -> ('Kindle',), Support: 0.2800, Confidence: 0.5385\n",
            "Rule: ('Kindle',) -> ('Smartwatch',), Support: 0.2400, Confidence: 0.5000\n",
            "Rule: ('Stand',) -> ('Smartwatch',), Support: 0.2400, Confidence: 0.7500\n",
            "Rule: ('Kindle',) -> ('Headset',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Headset',) -> ('Kindle',), Support: 0.2800, Confidence: 0.8750\n",
            "Rule: ('Headset',) -> ('Cable',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Kindle', 'Headset') -> ('Cable',), Support: 0.2000, Confidence: 0.7143\n",
            "Rule: ('Kindle', 'Cable') -> ('Headset',), Support: 0.2000, Confidence: 0.7143\n",
            "Rule: ('Headset', 'Cable') -> ('Kindle',), Support: 0.2000, Confidence: 1.0000\n",
            "Rule: ('Headset',) -> ('Kindle', 'Cable'), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Smartwatch',) -> ('Fire',), Support: 0.3200, Confidence: 0.5000\n",
            "Rule: ('Fire',) -> ('Smartwatch',), Support: 0.3200, Confidence: 0.6667\n",
            "Rule: ('Cable',) -> ('Fire',), Support: 0.2800, Confidence: 0.5385\n",
            "Rule: ('Fire',) -> ('Cable',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Smartwatch', 'Cable') -> ('Fire',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Smartwatch', 'Fire') -> ('Cable',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Cable', 'Fire') -> ('Smartwatch',), Support: 0.2000, Confidence: 0.7143\n",
            "Rule: ('Kindle',) -> ('Echo',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Echo',) -> ('Kindle',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Smartwatch',) -> ('Echo',), Support: 0.3200, Confidence: 0.5000\n",
            "Rule: ('Echo',) -> ('Smartwatch',), Support: 0.3200, Confidence: 0.6667\n",
            "Rule: ('Charger',) -> ('Fire',), Support: 0.2800, Confidence: 0.6364\n",
            "Rule: ('Fire',) -> ('Charger',), Support: 0.2800, Confidence: 0.5833\n",
            "Rule: ('Charger',) -> ('Smartwatch',), Support: 0.2800, Confidence: 0.6364\n",
            "Rule: ('Speaker',) -> ('Echo',), Support: 0.2400, Confidence: 0.6000\n",
            "Rule: ('Echo',) -> ('Speaker',), Support: 0.2400, Confidence: 0.5000\n",
            "Rule: ('Speaker',) -> ('Fire',), Support: 0.2000, Confidence: 0.5000\n",
            "Rule: ('Speaker',) -> ('Smartwatch',), Support: 0.2400, Confidence: 0.6000\n",
            "Rule: ('Speaker', 'Smartwatch') -> ('Echo',), Support: 0.2000, Confidence: 0.8333\n",
            "Rule: ('Speaker', 'Echo') -> ('Smartwatch',), Support: 0.2000, Confidence: 0.8333\n",
            "Rule: ('Smartwatch', 'Echo') -> ('Speaker',), Support: 0.2000, Confidence: 0.6250\n",
            "Rule: ('Speaker',) -> ('Smartwatch', 'Echo'), Support: 0.2000, Confidence: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Performance Comparison\n",
        "print(\"\\nPerformance Comparison:\")\n",
        "print(f\"Brute Force Time: {bf_time:.4f} seconds\")\n",
        "print(f\"Apriori Time: {apriori_time:.4f} seconds\")\n",
        "print(f\"FP-Growth Time: {fpgrowth_time:.4f} seconds\")\n",
        "\n",
        "\n",
        "fastest_algorithm = min([('Brute Force', bf_time), ('Apriori', apriori_time), ('FP-Growth', fpgrowth_time)], key=lambda x: x[1])\n",
        "print(f\"The fastest algorithm is {fastest_algorithm[0]} with a time of {fastest_algorithm[1]:.4f} seconds.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DA5eN_Dig6Xc",
        "outputId": "7098bb69-7886-4187-97e6-0111762ad128"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Performance Comparison:\n",
            "Brute Force Time: 0.0082 seconds\n",
            "Apriori Time: 0.0133 seconds\n",
            "FP-Growth Time: 0.0063 seconds\n",
            "The fastest algorithm is FP-Growth with a time of 0.0063 seconds.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare the number of frequent itemsets generated by each algorithm\n",
        "print(\"\\nNumber of Frequent Itemsets Generated:\")\n",
        "print(f\"Brute Force: {len(frequent_itemsets)}\")\n",
        "print(f\"Apriori: {len(frequent_itemsets_apriori)}\")\n",
        "print(f\"FP-Growth: {len(frequent_itemsets_fpgrowth)}\")\n",
        "\n",
        "# Algorithm with Most Itemsets\n",
        "most_itemsets = max([('Brute Force', len(frequent_itemsets)), ('Apriori', len(frequent_itemsets_apriori)), ('FP-Growth', len(frequent_itemsets_fpgrowth))], key=lambda x: x[1])\n",
        "print(f\"The algorithm that generated the most frequent itemsets is {most_itemsets[0]} with {most_itemsets[1]} itemsets.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPuFIPQCoG_-",
        "outputId": "8f20a574-d8ce-422e-e513-02cf2ce82064"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of Frequent Itemsets Generated:\n",
            "Brute Force: 31\n",
            "Apriori: 31\n",
            "FP-Growth: 31\n",
            "The algorithm that generated the most frequent itemsets is Brute Force with 31 itemsets.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    }
  ]
}