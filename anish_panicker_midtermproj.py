# -*- coding: utf-8 -*-
"""Anish_Panicker_midtermproj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1J6eK_Kx33McjgneJwbhy1dZeY1j5o4Ek
"""

import pandas as pd
import itertools
from collections import defaultdict
import time
from mlxtend.frequent_patterns import apriori, association_rules, fpgrowth

datasets = {
    1: 'amazon_items.csv',
    2: 'bestbuy_items.csv',
    3: 'kmart_items.csv',
    4: 'target_items.csv',
    5: 'walmart_items.csv'
}

print("Available Datasets:")
for key, value in datasets.items():
    print(f"{key}: {value}")

dataset_choice = int(input("Enter the dataset number you want to load (1-5): "))

if dataset_choice in datasets:
    dataset_path = datasets[dataset_choice]
    df = pd.read_csv(dataset_path)
    print(f"\nLoaded dataset from: {dataset_path}")
    print(df.head())

    transactions = df['Items'].apply(lambda x: x.split(', ')).tolist()
    all_items = sorted(set(item for transaction in transactions for item in transaction))

    print("Transactions:", transactions)
    print("Number of Transactions:", len(transactions))
    print("All Unique Items:", all_items)
    print("Number of Unique Items:", len(all_items))
else:
    print("Invalid choice. Please select a number between 1 and 5.")

min_support = float(input("Enter the minimum support value: "))
min_confidence = float(input("Enter the minimum confidence value: "))

transaction_df = pd.DataFrame([{item: (item in transaction) for item in all_items} for transaction in transactions])

def generate_candidates(itemset, length):
    """Generate all combinations of itemsets of a given length."""
    return list(itertools.combinations(itemset, length))

def calculate_support(itemset, transactions):
    """Calculate support of an itemset."""
    count = 0
    for transaction in transactions:
        if all(item in transaction for item in itemset):
            count += 1
    return count / len(transactions)

def generate_frequent_itemsets(transactions, all_items, min_support):

    frequent_itemsets = []
    k = 1
    while True:
        candidate_itemsets = generate_candidates(all_items, k)
        current_frequent_itemsets = []


        for itemset in candidate_itemsets:
            support = calculate_support(itemset, transactions)
            if support >= min_support:
                current_frequent_itemsets.append((itemset, support))

        if not current_frequent_itemsets:
            break


        frequent_itemsets.extend(current_frequent_itemsets)
        k += 1

    return frequent_itemsets


start_time = time.time()
frequent_itemsets = generate_frequent_itemsets(transactions, all_items, min_support)
end_time = time.time()
bf_time = end_time - start_time

print("\nFrequent Itemsets:")
for itemset, support in frequent_itemsets:
    print(f"Itemset: {itemset}, Support: {support}")

def generate_association_rules(frequent_itemsets, min_confidence):
    rules = []
    for itemset, support in frequent_itemsets:
        if len(itemset) < 2:
            continue
        for i in range(1, len(itemset)):
            antecedents = list(itertools.combinations(itemset, i))
            for antecedent in antecedents:
                consequent = tuple(item for item in itemset if item not in antecedent)
                antecedent_support = calculate_support(antecedent, transactions)
                if antecedent_support > 0:
                    confidence = support / antecedent_support
                    if confidence >= min_confidence:
                        rules.append((antecedent, consequent, support, confidence))
    return rules

association_rules_bf = generate_association_rules(frequent_itemsets, min_confidence)
print("\nAssociation Rules (Brute Force):")
for antecedent, consequent, support, confidence in association_rules_bf:
    print(f"Rule: {antecedent} -> {consequent}, Support: {support}, Confidence: {confidence}")

# Apriori
start_time = time.time()
frequent_itemsets_apriori = apriori(transaction_df, min_support=min_support, use_colnames=True)
end_time = time.time()
apriori_time = end_time - start_time

association_rules_apriori = association_rules(frequent_itemsets_apriori, metric="confidence", min_threshold=min_confidence)

print("\nFrequent Itemsets (Apriori):")
print(frequent_itemsets_apriori)
print("\nAssociation Rules (Apriori):")
for _, row in association_rules_apriori.iterrows():
    print(f"Rule: {tuple(row['antecedents'])} -> {tuple(row['consequents'])}, Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}")

# FP-Growth
start_time = time.time()
frequent_itemsets_fpgrowth = fpgrowth(transaction_df, min_support=min_support, use_colnames=True)
end_time = time.time()
fpgrowth_time = end_time - start_time

association_rules_fpgrowth = association_rules(frequent_itemsets_fpgrowth, metric="confidence", min_threshold=min_confidence)

print("\nFrequent Itemsets (FP-Growth):")
print(frequent_itemsets_fpgrowth)
print("\nAssociation Rules (FP-Growth):")
for _, row in association_rules_fpgrowth.iterrows():
    print(f"Rule: {tuple(row['antecedents'])} -> {tuple(row['consequents'])}, Support: {row['support']:.4f}, Confidence: {row['confidence']:.4f}")

# Performance Comparison
print("\nPerformance Comparison:")
print(f"Brute Force Time: {bf_time:.4f} seconds")
print(f"Apriori Time: {apriori_time:.4f} seconds")
print(f"FP-Growth Time: {fpgrowth_time:.4f} seconds")


fastest_algorithm = min([('Brute Force', bf_time), ('Apriori', apriori_time), ('FP-Growth', fpgrowth_time)], key=lambda x: x[1])
print(f"The fastest algorithm is {fastest_algorithm[0]} with a time of {fastest_algorithm[1]:.4f} seconds.")

# Compare the number of frequent itemsets generated by each algorithm
print("\nNumber of Frequent Itemsets Generated:")
print(f"Brute Force: {len(frequent_itemsets)}")
print(f"Apriori: {len(frequent_itemsets_apriori)}")
print(f"FP-Growth: {len(frequent_itemsets_fpgrowth)}")

# Algorithm with Most Itemsets
most_itemsets = max([('Brute Force', len(frequent_itemsets)), ('Apriori', len(frequent_itemsets_apriori)), ('FP-Growth', len(frequent_itemsets_fpgrowth))], key=lambda x: x[1])
print(f"The algorithm that generated the most frequent itemsets is {most_itemsets[0]} with {most_itemsets[1]} itemsets.")